{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13204d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "from itertools import islice\n",
    "\n",
    "nb_dir = Path.cwd()\n",
    "project_root = nb_dir.parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from rich import print, inspect\n",
    "\n",
    "from scripts.text_matching import normalise_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6110e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# people_file = Path(\"../in_progress/people_prepped.json\")\n",
    "people_file_grouped = Path(\"../in_progress/people_grouped_testing.json\")\n",
    "Path(\"data/people/people_records_prepped.json\")\n",
    "# people_grouped_file = Path(\"../in_progress/people_grouped.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c45021",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_keywords = [\"stiftung\", \"archiv\", \"gesellschaft\", \"forum\", \"gemeinde\", \"sammlung\", \"institut\", \"museum\", \"kultur\", \"kuratorium\", \"verlag\", \"ministerium\", \"akademie\", \"trust\", \"verein\", \"organisation\", \"vereinigung\", \"universitÃ¤t\", \"bibliothek\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b86cc4",
   "metadata": {},
   "source": [
    "Create a lookup dict to group all entries by their unified_id. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f39d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# people_dict = {}\n",
    "# people_entries = []\n",
    "\n",
    "# with open(people_file, \"r\") as f:\n",
    "#     people_entries = json.load(f)\n",
    "#     # print(people_entries)\n",
    "\n",
    "# for entry in people_entries:\n",
    "#     unified_id = entry[\"unified_id\"]\n",
    "#     people_dict.setdefault(unified_id, []).append(entry)\n",
    "\n",
    "# sorted_entries = sorted(people_dict.items())\n",
    "# sorted_dict = dict(sorted_entries)\n",
    "# # print(sorted_dict)\n",
    "# with open(people_grouped_file, \"w\") as f:\n",
    "#     json.dump(sorted_dict, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622fda7d",
   "metadata": {},
   "source": [
    "Next steps: \n",
    "\n",
    "loop through grouped people: \n",
    "- count entries\n",
    "- check if any of the organisation keywords are present in the display name, if yes: set is_organisation = True\n",
    "- if single_name = not null AND is_author = True: pass, if not: set single_name to null\n",
    "- if entry count +1 \n",
    "- score each entry\n",
    "    - each filled name field +1 \n",
    "    - any name field has diacritics +2\n",
    "  \n",
    "- create a dictionary/list(?) with authority record from the entry with the highest score with the fields for the people table, each person exists only once. Save as json.\n",
    "- create a dictionary/list(?) with one entry for each individual book/mention with the required database fields. These need to have a definitive link to the person record using the composite_id because the current \"book_id\" was created during a previous database load that will need to be removed. Save as json. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17df132",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_records = []\n",
    "book2people_records = []\n",
    "people_overview_records = {}\n",
    "\n",
    "with open(people_file_grouped, \"r\") as f:\n",
    "    people_grouped = json.load(f)\n",
    "\n",
    "for unified_id, entries in islice(people_grouped.items(), 35):\n",
    "# for unified_id, entries in people_grouped.items():\n",
    "    entry_count = len(entries)\n",
    "\n",
    "    all_family = set()\n",
    "    all_given = set()\n",
    "    all_particles = set()\n",
    "    all_single = set()\n",
    "    # print(unified_id, entries)\n",
    "    entries_list = []\n",
    "\n",
    "    for entry in entries:\n",
    "\n",
    "        display_name = entry[\"display_name\"]\n",
    "        display_lower = display_name.lower()\n",
    "        family_name = entry[\"family_name\"]\n",
    "        given_names = entry[\"given_names\"]\n",
    "        name_particles = entry[\"name_particles\"]\n",
    "        single_name = entry[\"single_name\"]\n",
    "        composite_id = entry[\"composite_id\"]\n",
    "        source_filename = entry[\"source_filename\"]\n",
    "        is_author = entry[\"is_author\"]\n",
    "        is_editor = entry[\"is_editor\"]\n",
    "        is_contributor = entry[\"is_contributor\"]\n",
    "        is_translator = entry[\"is_translator\"]\n",
    "        sort_order = entry[\"sort_order\"]\n",
    "\n",
    "        is_organisation = False\n",
    "\n",
    "        if any(keyword in display_lower for keyword in org_keywords):\n",
    "            is_organisation = True\n",
    "            print(f\"found an org!\")\n",
    "\n",
    "        if single_name and not is_author:\n",
    "            entry[\"single_name\"] = None\n",
    "            #print(f\"removed a name!\")\n",
    "\n",
    "        if family_name:\n",
    "           family_name = family_name.title()\n",
    "\n",
    "        if single_name:\n",
    "            single_name = single_name.title()\n",
    "\n",
    "            # this needs to use the original spelling\n",
    "        book2people_records.append({\n",
    "            \"composite_id\": composite_id,\n",
    "            \"source_filename\": source_filename,\n",
    "            \"unified_id\": unified_id,\n",
    "            \"display_name\": display_name,\n",
    "            \"family_name\": family_name,\n",
    "            \"given_names\": given_names,\n",
    "            \"name_particles\": name_particles,\n",
    "            \"single_name\": single_name,\n",
    "            \"is_author\": is_author,\n",
    "            \"is_editor\": is_editor,\n",
    "            \"is_contributor\": is_contributor,\n",
    "            \"is_translator\": is_translator,\n",
    "            \"sort_order\": sort_order\n",
    "        })\n",
    "\n",
    "        entries_list.append({\n",
    "            \"composite_id\": composite_id,\n",
    "            \"source_filename\": source_filename,\n",
    "            \"unified_id\": unified_id,\n",
    "            \"display_name\": display_name,\n",
    "            \"is_author\": is_author,\n",
    "            \"is_editor\": is_editor,\n",
    "            \"is_contributor\": is_contributor,\n",
    "            \"is_translator\": is_translator,\n",
    "            \"sort_order\": sort_order\n",
    "        })\n",
    "\n",
    "        if entry_count > 1:\n",
    "            score_family = 0\n",
    "            score_given = 0\n",
    "            score_particles = 0\n",
    "            score_single = 0\n",
    "\n",
    "            if family_name:\n",
    "                score_family = len(family_name)\n",
    "                if any(ord(char) > 127 for char in family_name):\n",
    "                    score_family += 2\n",
    "                all_family.add((score_family, family_name.title()))\n",
    "\n",
    "            if given_names:\n",
    "                score_given = len(given_names)\n",
    "                if any(ord(char) > 127 for char in given_names):\n",
    "                    score_given += 2\n",
    "                all_given.add((score_given, given_names))\n",
    "\n",
    "            if name_particles:\n",
    "                score_particles = len(name_particles)\n",
    "                if any(ord(char) > 127 for char in name_particles):\n",
    "                    score_particles += 2\n",
    "                all_particles.add((score_particles, name_particles))\n",
    "\n",
    "            if single_name:\n",
    "                score_single = len(single_name)\n",
    "                if any(ord(char) > 127 for char in single_name):\n",
    "                    score_single += 2\n",
    "                all_given.add((score_single, single_name))\n",
    "\n",
    "    best_family = max(all_family, default=(0, None))\n",
    "    best_given = max(all_given, default=(0, None))\n",
    "    best_particles = max(all_particles, default=(0, None))\n",
    "    best_single = max(all_single, default=(0, None))\n",
    "\n",
    "    if entry_count > 1:\n",
    "        family_name = best_family[1]\n",
    "        given_names = best_given[1]\n",
    "        name_particles = best_particles[1]\n",
    "        single_name = best_single[1]\n",
    "\n",
    "        # print(f\"all_family: {all_family} best_family: {best_family}, family_name: {family_name}\")\n",
    "        print(f\"all_given: {all_given} best_given: {best_given}\")\n",
    "        # print(f\"all_particle: {all_particles} best_particle: {best_particles}\")\n",
    "        # print(f\"all_single: {all_single} best_single: {best_single}\")\n",
    "\n",
    "    if single_name:\n",
    "        display_name = single_name\n",
    "    else:\n",
    "        display_name = \" \".join(filter(None, [given_names, name_particles, family_name]))\n",
    "    # print(display_name)\n",
    "\n",
    "    family_variants = [name for score, name in all_family]\n",
    "    given_variants = [name for score, name in all_given]\n",
    "    particles_variants = [name for score, name in all_particles]\n",
    "    single_variants = [name for score, name in all_single]\n",
    "\n",
    "    # print(family_variants)\n",
    "\n",
    "people_records.append({\n",
    "    \"unified_id\": unified_id,\n",
    "    \"family_name\": family_name,\n",
    "    \"given_names\": given_names,\n",
    "    \"name_particles\": name_particles,\n",
    "    \"single_name\": single_name,\n",
    "    \"is_organisation\": is_organisation\n",
    "})\n",
    "    # this should group everything AND store the variants in the \"all_... \" sets from the names\n",
    "people_overview_records.update({\n",
    "    \"unified_id\":\n",
    "        {\n",
    "        \"family_name\": family_name,\n",
    "        \"given_names\": given_names,\n",
    "        \"name_particles\": name_particles,\n",
    "        \"single_name\": single_name,\n",
    "        \"is_organisation\": is_organisation,\n",
    "        \"family_variants\": family_variants,\n",
    "        \"given_variants\": given_variants,\n",
    "        \"particles_variants\": particles_variants,\n",
    "        \"single_variants\": single_variants,\n",
    "        \"entries\": entries_list\n",
    "        }\n",
    "    })\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
