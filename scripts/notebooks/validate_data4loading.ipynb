{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "db09f46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from rich import print as rprint\n",
    "from collections import defaultdict\n",
    "\n",
    "from pathlib import Path\n",
    "from itertools import islice\n",
    "\n",
    "nb_dir = Path.cwd()\n",
    "\n",
    "project_root = nb_dir.parent.parent\n",
    "\n",
    "sys.path.insert(0, str(project_root))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "78811ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_records_prepped_file = Path(project_root / \"data/people/people_records_prepped.json\")\n",
    "books2people_prepped_file = Path(project_root / \"data/people/books2people_prepped.json\")\n",
    "people_records_validated_file = Path(project_root / \"data/people/people_records_validated.json\")\n",
    "folder_matched = Path(project_root / \"data/matched\")\n",
    "folder_validated = Path(project_root / \"data/validated\")\n",
    "\n",
    "validation_failed_log_file = Path(project_root / \"data/logs/validation_failed_log.json\")\n",
    "validation_report_log_file = Path(project_root / \"data/logs/validation_report_log.json\")\n",
    "validation_log_file = Path(project_root / \"data/logs/validation_log.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "041b2f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_records = []\n",
    "books2people_records = []\n",
    "\n",
    "with open(people_records_prepped_file, \"r\") as f:\n",
    "    people_records = json.load(f)\n",
    "\n",
    "with open(books2people_prepped_file, \"r\") as f:\n",
    "    books2people_records = json.load(f)\n",
    "\n",
    "books2people_dict = defaultdict(list)\n",
    "for entry in books2people_records:\n",
    "    books2people_dict[entry[\"composite_id\"]].append(entry)\n",
    "\n",
    "people_dict = {person[\"unified_id\"]: person for person in people_records}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349887ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# all failed entries will be collected, grouped by file name. They will be separated between \"not_found\" for those where the composite_id doesn't appear in the lookup dict, and those where the expected total and counted total of people don't match OR have an \"oops\" unified_id will be in \"issues\". There I'll save the full entry + the\n",
    "# All validated entries will be collected in the report, grouped by file. If there is a mismatch between expected and actual roles, the entire entry will be stored, together with a report. If there are no issues, only the composite_id will be stored.\n",
    "\n",
    "processed_file_count = 0\n",
    "validated_entries_total = 0\n",
    "failed_entries_total = 0\n",
    "\n",
    "failed_entries = {}\n",
    "validated_report = {}\n",
    "validation_log = {}\n",
    "people_not_validated = {}\n",
    "people_validated = []\n",
    "unified_id_found = set()\n",
    "\n",
    "for file in folder_matched.iterdir():\n",
    "    validated_entries = {}\n",
    "    validated_count = 0\n",
    "    validated_with_issues_count = 0\n",
    "    not_found_count = 0\n",
    "    failed_count = 0\n",
    "    entry_count = 0\n",
    "    ids_found = 0\n",
    "\n",
    "    validated_report[file.stem] = {\n",
    "        \"issues\": {},\n",
    "        \"no_issues\": []\n",
    "    }\n",
    "\n",
    "\n",
    "    failed_entries[file.stem] = {\n",
    "        \"not_found\": {},\n",
    "        \"issues\": {}\n",
    "    }\n",
    "\n",
    "\n",
    "    if not file.exists():\n",
    "        raise FileNotFoundError(f\"{file} doesn't exist!\")\n",
    "\n",
    "    with open(file, \"r\") as f:\n",
    "        books = json.load(f)\n",
    "        #rprint(books)\n",
    "        processed_file_count += 1\n",
    "\n",
    "    for composite_id, book in books.items():\n",
    "        entry_count += 1\n",
    "        authors = book[\"parsed_entry\"].get(\"authors\") or []\n",
    "        editors = book[\"parsed_entry\"].get(\"editors\") or []\n",
    "        contributors = book[\"parsed_entry\"].get(\"contributors\") or []\n",
    "        translator = book[\"parsed_entry\"][\"translator\"]\n",
    "        is_translation = book[\"parsed_entry\"][\"is_translation\"]\n",
    "\n",
    "        authors_exp = len(authors)\n",
    "        editors_exp = len(editors)\n",
    "        contributors_exp = len(contributors)\n",
    "        translator_exp = 1 if translator else 0\n",
    "        expected_total = authors_exp + editors_exp + contributors_exp + translator_exp\n",
    "        # print(expected_total)\n",
    "\n",
    "\n",
    "        # validation logic goes here\n",
    "        if composite_id in books2people_dict:\n",
    "            ids_found += 1\n",
    "            books2people_data = books2people_dict[composite_id]\n",
    "            unified_ids_in_book = [entry[\"unified_id\"] for entry in books2people_data]\n",
    "\n",
    "            author_count = 0\n",
    "            editor_count = 0\n",
    "            contributor_count = 0\n",
    "            translator_count = 0\n",
    "            total = 0\n",
    "            author_mismatch_count = 0\n",
    "            editor_mismatch_count = 0\n",
    "            contributor_mismatch_count = 0\n",
    "            translator_mismatch_count = 0\n",
    "\n",
    "\n",
    "            author_mismatch = False\n",
    "            editor_mismatch = False\n",
    "            contributor_mismatch = False\n",
    "            translator_mismatch = False\n",
    "\n",
    "            for entry in books2people_data:\n",
    "                unified_id = entry[\"unified_id\"]\n",
    "                is_author = entry[\"is_author\"]\n",
    "                is_editor = entry[\"is_editor\"]\n",
    "                is_contributor = entry[\"is_contributor\"]\n",
    "                is_translator = entry[\"is_translator\"]\n",
    "\n",
    "                oops_id = False\n",
    "\n",
    "                if unified_id == \"oops\":\n",
    "                    oops_id = True\n",
    "                    failed_entries[file.stem][\"issues\"][composite_id] = {\n",
    "                        \"book\": book,\n",
    "                        \"report\": {\n",
    "                            \"oops\": oops_id\n",
    "                        }\n",
    "                    }\n",
    "                    failed_entries_total += 1\n",
    "                    continue\n",
    "\n",
    "                if is_author:\n",
    "                    author_count += 1\n",
    "                    total +=1\n",
    "\n",
    "                if is_editor:\n",
    "                    editor_count += 1\n",
    "                    total +=1\n",
    "\n",
    "                if is_contributor:\n",
    "                    contributor_count += 1\n",
    "                    total +=1\n",
    "\n",
    "                if is_translator:\n",
    "                   translator_count += 1\n",
    "                   total +=1\n",
    "\n",
    "            if not authors_exp == author_count:\n",
    "                author_mismatch = True\n",
    "                author_mismatch_count += 1\n",
    "\n",
    "            if not editors_exp == editor_count:\n",
    "                editor_mismatch = True\n",
    "                editor_mismatch_count += 1\n",
    "\n",
    "            if not contributors_exp == contributor_count:\n",
    "                contributor_mismatch = True\n",
    "                contributor_mismatch_count += 1\n",
    "\n",
    "            if not translator_exp == translator_count:\n",
    "                translator_mismatch = True\n",
    "                translator_mismatch_count +=1\n",
    "\n",
    "            # Check whether the overall count matches - this currently decides whether an entry fails or not\n",
    "            if not expected_total == total:\n",
    "                totals_mismatch = True\n",
    "                failed_entries[file.stem][\"issues\"][composite_id] = {\n",
    "                    \"book\": book,\n",
    "                    \"books2people\": books2people_data,\n",
    "                    \"report\": {\n",
    "                        \"expected_total\": expected_total,\n",
    "                        \"found total\": total,\n",
    "                        \"authors_exp\": authors_exp,\n",
    "                        \"authors\": author_count,\n",
    "                        \"editors_exp\": editors_exp,\n",
    "                        \"editors\": editor_count,\n",
    "                        \"contributors_exp\": contributors_exp,\n",
    "                        \"contributors\": contributor_count,\n",
    "                        \"translator_exp\": translator_exp,\n",
    "                        \"translator\": translator_count\n",
    "                    }\n",
    "                }\n",
    "                failed_count +=1\n",
    "\n",
    "            # overall number of people matches, counts as validated\n",
    "            else:\n",
    "                totals_mismatch = False\n",
    "\n",
    "                # check people data\n",
    "                unified_id_found.update(unified_ids_in_book)\n",
    "\n",
    "                has_role_mismatch = any([author_mismatch, editor_mismatch, contributor_mismatch, translator_mismatch])\n",
    "                if not oops_id and not has_role_mismatch:\n",
    "                    validated_entries[composite_id] = {\n",
    "                        \"books\": book[\"parsed_entry\"],\n",
    "                        \"admin\":book[\"parsed_entry\"].pop(\"administrative\"),\n",
    "                        \"books2people\": books2people_data\n",
    "                    }\n",
    "                    validated_report[file.stem][\"no_issues\"].append(composite_id)\n",
    "                    validated_count +=1\n",
    "\n",
    "                if not oops_id and has_role_mismatch:\n",
    "                    validated_with_issues_count +=1\n",
    "                    validated_entries[composite_id] = {\n",
    "                        \"books\": book[\"parsed_entry\"],\n",
    "                        \"admin\":book[\"parsed_entry\"].pop(\"administrative\"),\n",
    "                        \"books2people\": books2people_data\n",
    "                    }\n",
    "                    validated_report[file.stem][\"issues\"][composite_id] = {\n",
    "                    \"book\": book,\n",
    "                    \"report\": {\n",
    "                        \"expected_total\": expected_total,\n",
    "                        \"found total\": total,\n",
    "                        \"authors_exp\": authors_exp,\n",
    "                        \"authors\": author_count,\n",
    "                        \"editors_exp\": editors_exp,\n",
    "                        \"editors\": editor_count,\n",
    "                        \"contributors_exp\": contributors_exp,\n",
    "                        \"contributors\": contributor_count,\n",
    "                        \"translator_exp\": translator_exp,\n",
    "                        \"translator\": translator_count\n",
    "                    }\n",
    "                }\n",
    "\n",
    "        else:\n",
    "            failed_entries[file.stem][\"not_found\"][composite_id] = {\"book\": book}\n",
    "            not_found_count += 1\n",
    "\n",
    "\n",
    "    percent = (ids_found / entry_count ) * 100\n",
    "\n",
    "    validation_log[file.stem] = {\n",
    "        \"books\": entry_count,\n",
    "        \"matched\": f\"{percent:.2f}%\",\n",
    "        \"not_found\": not_found_count,\n",
    "        \"validated\": validated_count,\n",
    "        \"validated_with_issues\": validated_with_issues_count,\n",
    "        \"failed\": failed_count\n",
    "    }\n",
    "\n",
    "    # write validated topic files:\n",
    "    validated_path = folder_validated / file.name\n",
    "\n",
    "    with open(validated_path, \"w\") as f:\n",
    "        json.dump(validated_entries, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "for unified_id, person in people_dict.items():\n",
    "    if unified_id not in unified_id_found:\n",
    "        people_not_validated[unified_id] = person\n",
    "    else:\n",
    "        people_validated.append(person)\n",
    "\n",
    "\n",
    "with open(validation_failed_log_file, \"w\") as f:\n",
    "    json.dump(failed_entries, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(validation_report_log_file, \"w\") as f:\n",
    "    json.dump(validation_log, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(validation_report_log_file, \"w\") as f:\n",
    "    json.dump(validated_report, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(people_records_validated_file, \"w\") as f:\n",
    "    json.dump(people_validated, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "rprint(validation_log)\n",
    "# rprint(failed_entries)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
